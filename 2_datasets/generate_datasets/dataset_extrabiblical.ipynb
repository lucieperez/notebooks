{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0384d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from tfob import TFOb, get_xb\n",
    "\n",
    "XB = get_xb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46394808",
   "metadata": {},
   "source": [
    "### 1.Create a dataset with all motion verbs (in predicative phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f940bf",
   "metadata": {},
   "source": [
    "#### 1.1 List of wanted motion verbs, adapted for the extrabiblical database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_verbs = ['BW>[','HLK[','JY>[','JRD[','<BR[',\n",
    "                '<LH[','CWB[','>TH[','BRX[','GJX[',\n",
    "                'GLH[','GLL[','DXP[','DLG[','HWH[',\n",
    "                'XWC[','XLP[','XSH[','VB<[','VWF[',\n",
    "                'MHR[','MWC[','NGC[','NHR[','NWX[',\n",
    "                'NWS[','NXT[','NVP[','NS<[','NPL[',\n",
    "                'NTK[','SBB[','SWR[','SLQ[','<WZ[',\n",
    "                '<WP[','PNH[','PF<[','YWP[','Y<D[',\n",
    "                'QHL[','QPY[','QRB[','RWY[','FVH[',\n",
    "                'CWX[','CWR=[','CVP[','CQQ[','T>R[',\n",
    "                'T<H[']\n",
    "\n",
    "motion_verbs = [verb.replace(\"[\", \"\") for verb in motion_verbs]\n",
    "#motion_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6665fd",
   "metadata": {},
   "source": [
    "#### 1.2 List of the scrolls I want in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = TFOb.all(\"book\", XB).book\n",
    "books.remove(\"Shirata\")\n",
    "books.remove(\"Pirqe\")\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFOb.all(\"book\", XB)._levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6902b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the phrases being predicates\n",
    "\n",
    "phrases = TFOb.all(\"book\", XB).filter_in(book=books).to_phrases.filter(function=\"Pred\")\n",
    "# List of verbs in predicative phrases\n",
    "verbs = phrases.to_words.filter_in(lex=motion_verbs)\n",
    "\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3081f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(verbs.book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04089067",
   "metadata": {},
   "source": [
    "### 2. Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f07b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(g_cons):\n",
    "    return g_cons.replace(\"_\", \" \").replace(\"×³\", \"\").replace(\"'\", \"\")\n",
    "\n",
    "\n",
    "def find_clause(verb):\n",
    "    \"\"\"Find the complement of a verb. If no match, returns None\"\"\"\n",
    "    clause = verb.to_clauses.to_clauses\n",
    "    return clause\n",
    "\n",
    "\n",
    "def find_complements(verb):\n",
    "    \"\"\"Find the complement of a verb. If no match, returns None\"\"\"\n",
    "    complements = verb.to_clauses.to_phrases.filter(function=\"Cmpl\")\n",
    "    return complements\n",
    "\n",
    "\n",
    "def find_subject(verb):\n",
    "    \"\"\"Find the subject of a verb. If no match, returns None\"\"\"\n",
    "    subjects = verb.to_clauses.to_phrases.filter(function=\"Subj\")\n",
    "    assert len(subjects) <= 1\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eef1fa",
   "metadata": {},
   "source": [
    "### 3. Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32dedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "complements = []\n",
    "\n",
    "for verb in verbs:\n",
    "    cmpl = verb.to_clauses.to_phrases.filter(function=\"Cmpl\")\n",
    "    if cmpl:\n",
    "        complements.append(cmpl)\n",
    "        \n",
    "len(complements)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with the occurrences\n",
    "\n",
    "\n",
    "items = [] # create an empty list to store all the information for each occ.\n",
    "\n",
    "       \n",
    "for verb in verbs:\n",
    "    \n",
    "    # Add the scroll name\n",
    "    scroll = verb.book[0]\n",
    "    verse = verb.to_verses\n",
    "    sign_info = \"\"\n",
    "    clause = find_clause(verb)\n",
    "    subject = find_subject(verb)\n",
    "    complements = find_complements(verb)\n",
    "    dir_he_dss_verse = \"\"\n",
    "    \n",
    "    if not complements:\n",
    "        complements = [\"\"]\n",
    "        dir_he = \"\"\n",
    "\n",
    "\n",
    "    for complement in complements: \n",
    "        \n",
    "        if complement != \"\":\n",
    "            dir_he = int(\"H\" in complement.to_words.uvf[0])\n",
    "    \n",
    "        # Collect information about the following variables:    \n",
    "        item = {\n",
    "            \"verb_id\": verb.ids[0], \n",
    "            \"lex\": verb.lex[0], \n",
    "            \"scroll\": scroll,\n",
    "            \"book\": verb.book[0], \n",
    "            \"chapter\": verb.chapter[0], \n",
    "            \"verse_num\": verb.verse[0],\n",
    "            \"gcons_verb\": clean(verb.g_cons[0]),\n",
    "            \"gcons_verse\": clean(str(verse)),\n",
    "            \"gcons_clause\": clean(str(find_clause(verb))),\n",
    "            \"subject\": clean(str(subject)),\n",
    "            \"complement\": clean(str(complement)),\n",
    "            \"dir_he\": dir_he,\n",
    "            \"sign_info\": sign_info,\n",
    "            \"stem\": verb.vs[0],\n",
    "            \"tense\": verb.vt[0],\n",
    "        }\n",
    "        \n",
    "        if complement != \"\": \n",
    "            prepositions = complement.to_words.filter(sp=\"prep\").lex\n",
    "            n = 0\n",
    "            for preposition in prepositions:\n",
    "                n += 1\n",
    "                item[f\"preposition_{n}\"] = str(preposition)\n",
    "                \n",
    "        items.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c4628-3c79-477d-a6b8-1755cdff95a4",
   "metadata": {},
   "source": [
    "### 3.4 Create the dataset with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(items).fillna(\"\")\n",
    "df.sort_values([\"book\", \"chapter\", \"verse_num\"], ascending=[True, True, True], ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b434cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b5b53-c8aa-4662-a8e4-1f1d801f5265",
   "metadata": {},
   "source": [
    "### 3.5 Save the dataset in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c7484-0f3c-491c-909d-6b6f0d3260a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/extrabiblical_all_verbs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91427bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
