{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62cd6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:02:43.667198Z",
     "start_time": "2023-04-07T15:02:43.664467Z"
    }
   },
   "outputs": [],
   "source": [
    "from munch import Munch\n",
    "from tf.app import use\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d882c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:03:08.551309Z",
     "start_time": "2023-04-07T15:02:44.174880Z"
    }
   },
   "outputs": [],
   "source": [
    "B = use(\"etcbc/dss\", hoist=globals())\n",
    "DSS = Munch({\"F\": F, \"L\": L, \"T\": T, \"name\": \"DSS\", \"A\": B})\n",
    "\n",
    "A = use(\"etcbc/bhsa\", hoist=globals())\n",
    "BHSA = Munch({\"F\": F, \"L\": L, \"T\": T, \"name\": \"BHSA\", \"A\": A})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6170b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:39:54.801853Z",
     "start_time": "2023-04-07T15:39:54.792075Z"
    }
   },
   "outputs": [],
   "source": [
    "del F, L, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a487161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:03:27.651909Z",
     "start_time": "2023-04-07T15:03:27.567877Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a6ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:26:56.105048Z",
     "start_time": "2023-04-07T15:26:56.095944Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "from itertools import chain\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55e127",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:27:34.283545Z",
     "start_time": "2023-04-07T15:27:29.463929Z"
    }
   },
   "outputs": [],
   "source": [
    "dss_sections = {}\n",
    "for word in DSS.F.otype.s(\"word\"):    \n",
    "    scroll = DSS.T.scrollName(DSS.L.u(word, \"scroll\")[0])\n",
    "    book = DSS.F.book_etcbc.v(word)    \n",
    "    chapter = DSS.F.chapter.v(word)\n",
    "    verse = DSS.F.verse.v(word)    \n",
    "    if None in (scroll, book, chapter, verse):\n",
    "        continue\n",
    "    section = (book, chapter, verse)\n",
    "    dss_sections.setdefault(section, {}).setdefault(scroll, []).append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87303cad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T16:17:44.401008Z",
     "start_time": "2023-04-07T16:17:44.382705Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(iterable):\n",
    "    return list(dict.fromkeys(iterable))\n",
    "\n",
    "\n",
    "class TFOb:\n",
    "    def __init__(self, ids, source):\n",
    "        if type(ids) is int:\n",
    "            ids = [ids]\n",
    "        self.ids = remove_duplicates(ids)\n",
    "        self.source = source\n",
    "        self._levels = [\"to_\" + otype + \"s\" for otype in source.F.otype.all]\n",
    "        \n",
    "    @classmethod\n",
    "    def all(self, level, source):\n",
    "        return TFOb(list(source.F.otype.s(level)), source)\n",
    "        \n",
    "    @classmethod\n",
    "    def section(self, section, source, scroll=None):\n",
    "        if source.name == \"BHSA\":\n",
    "            return TFOb(source.T.nodeFromSection(section), source)\n",
    "        \n",
    "        section = (section[0], str(section[1]), str(section[2]))\n",
    "        dss_section = dss_sections[section]\n",
    "        if scroll is None:\n",
    "            scroll = list(dss_section.keys())[0]\n",
    "        return TFOb(dss_section[scroll], source)\n",
    "        \n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self._levels:\n",
    "            level = \"to_\" + self.level + \"s\"\n",
    "            if self.level == \"none\":\n",
    "                return self\n",
    "            level_index = self._levels.index(level)\n",
    "            new_level_index = self._levels.index(attr)\n",
    "            if new_level_index > level_index:\n",
    "                return self.down(attr[3:-1])\n",
    "            elif new_level_index < level_index:\n",
    "                return self.up(attr[3:-1])\n",
    "            else:\n",
    "                return self\n",
    "            \n",
    "        if self.source.name == \"DSS\" and attr == \"lex\":\n",
    "            attr = \"lex_etcbc\"\n",
    "            \n",
    "        feature = getattr(self.source.F, attr)\n",
    "        return [getattr(self.source.F, attr).v(id_) for id_ in self.ids]\n",
    "    \n",
    "    def copy(self):\n",
    "        return TFOb(self.ids.copy(), source)\n",
    "\n",
    "    def up(self, otype=None):\n",
    "        if self.level in (otype, \"none\"):\n",
    "            return self\n",
    "        return TFOb(\n",
    "            chain(*[self.source.L.u(id_, otype) for id_ in self.ids]),\n",
    "            source=self.source,\n",
    "        )\n",
    "\n",
    "    def down(self, otype=None):\n",
    "        if self.level in (otype, \"none\"):\n",
    "            return self\n",
    "        return TFOb(\n",
    "            chain(*[self.source.L.d(id_, otype) for id_ in self.ids]),\n",
    "            source=self.source,\n",
    "        )\n",
    "\n",
    "    def filter(self, **kwargs):\n",
    "        ids = []\n",
    "        for id_ in self.ids:\n",
    "            for key, value in kwargs.items():\n",
    "                if key == \"lex\" and self.source.name == \"DSS\":\n",
    "                    key = \"lex_etcbc\"\n",
    "                if getattr(self.source.F, key).v(id_) != value:\n",
    "                    break\n",
    "            else:\n",
    "                ids.append(id_)\n",
    "        return TFOb(ids, source=self.source)\n",
    "\n",
    "    def first(self, **kwargs):\n",
    "        ids = []\n",
    "        for id_ in self.ids:\n",
    "            for key, value in kwargs.items():\n",
    "                if key == \"lex\" and self.source.name == \"DSS\":\n",
    "                    key = \"lex_etcbc\"\n",
    "                if getattr(self.source.F, key).v(id_) != value:\n",
    "                    break\n",
    "            else:\n",
    "                return TFOb(id_, source=self.source)\n",
    "        return TFOb([], source=self.source)\n",
    "            \n",
    "    def __getitem__(self, i):\n",
    "        return TFOb(self.ids[i], source=self.source)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    @property\n",
    "    def text(self):\n",
    "        return self.source.T.text(self.ids)\n",
    "    \n",
    "    def str(self, word_limit=None):\n",
    "        if self.level not in (\"word\", \"none\"):\n",
    "            return str(self.down(\"word\"))\n",
    "        if word_limit is not None and len(self) > word_limit:\n",
    "            return self[:word_limit // 2].str() + \" [...] \" + self[-word_limit // 2:].str()\n",
    "        else:\n",
    "            return \" \".join([g_cons for g_cons in self.g_cons if g_cons])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str()\n",
    "    \n",
    "    def __dir__(self):\n",
    "        return list(self.__dict__.keys()) + dir(self.source.F) + self._levels\n",
    "    \n",
    "    def __add__(self, ob):\n",
    "        return TFOb(self.ids + ob.ids, source=self.source)\n",
    "\n",
    "    @property\n",
    "    def level(self):\n",
    "        if len(self.ids) > 0:\n",
    "            return self.otype[0]\n",
    "        return \"none\"\n",
    "    \n",
    "    def pretty(self, extraFeatures=(\"sp\", \"function\")):\n",
    "        if len(self) == 0:\n",
    "            return\n",
    "        levels = self.source.F.otype.all\n",
    "        ob = self\n",
    "        level_index = levels.index(ob.level)\n",
    "        while len(ob) != 1:\n",
    "            level_index -= 1\n",
    "            ob = self.up(levels[level_index])\n",
    "        self.source.A.pretty(ob.ids[0], extraFeatures=extraFeatures)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        level = self.level\n",
    "        if level != \"none\":\n",
    "            level += \"s\"\n",
    "            \n",
    "        return f'<{self.level}_{len(self)} \"{self.str(40)}\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd46259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mt_isa_df_starter.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = TFOb.section([\"Isaiah\", 7, 6], BHSA).to_words.first(lex=\"<LH[\")\n",
    "complement = verb.to_clauses.to_phrases.filter(function=\"Cmpl\")\n",
    "preposition = complement.to_words.filter(sp=\"prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f69b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb(section, lexeme, source):\n",
    "    return TFOb.section(section, source).to_words.first(lex=lexeme)\n",
    "\n",
    "def get_verb_stem(section, lexeme, source):\n",
    "    verb = get_verb(section, lexeme, source)\n",
    "    return \"\".join(verb.vs)\n",
    "\n",
    "def get_verb_tense(section, lexeme, source):\n",
    "    verb = get_verb(section, lexeme, source)\n",
    "    return \"\".join(verb.vt) \n",
    "\n",
    "def get_verse(section, lexeme, source):\n",
    "    return TFOb.section(section, source)   \n",
    "    \n",
    "def get_clause(section, lexeme, source):\n",
    "    verb = get_verb(section, lexeme, source)\n",
    "    return verb.to_clauses\n",
    "\n",
    "def get_phrase(section, lexeme, source):\n",
    "    verb = get_verb(section, lexeme, source)\n",
    "    return verb.to_phrases\n",
    "\n",
    "def get_complements(section, lexeme, source):\n",
    "    verb = get_verb(section, lexeme, source)\n",
    "    phrases = verb.to_clauses.to_phrases\n",
    "    return phrases.filter(function=\"Cmpl\") + phrases.filter(function=\"Loca\")\n",
    "\n",
    "def get_prepositions(section, lexeme, source):\n",
    "    complements = get_complements(section, lexeme, source)\n",
    "    prepositions = []\n",
    "    for complement in complements:\n",
    "        prepositions.append(complement.to_words.filter(sp=\"prep\"))\n",
    "    return prepositions\n",
    "\n",
    "def get_subject(section, lexeme, source):\n",
    "    verb = get_verb(section, lexeme, source)\n",
    "    return verb.to_clauses.to_phrases.filter(function=\"Subj\")\n",
    "\n",
    "def get_verse_lex(section, lexeme, source):\n",
    "    verse = get_verse(section, lexeme, source)\n",
    "    return \" \".join(verse.to_words.lex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "columns_functions = {\n",
    "    \"verb_heb\": lambda *args: get_verb(*args).text, \n",
    "    \"verse_g_cons\": get_verse,\n",
    "    \"verse_heb\": lambda *args: get_verse(*args).text, \n",
    "    \"verb_stem\": get_verb_stem, \n",
    "    \"verb_tense\": get_verb_tense,\n",
    "    \"verb_phrase\": get_phrase, \n",
    "    \"verb_phrase_heb\": lambda *args: get_phrase(*args).text, \n",
    "    \"verb_clause\": get_clause, \n",
    "    \"verb_clause_heb\": lambda *args: get_clause(*args).text,\n",
    "    \"subject\": get_subject, \n",
    "    \"subj_heb\": lambda *args: get_subject(*args).text,\n",
    "    \"complement\": get_complements,\n",
    "    \"preposition\": get_prepositions,\n",
    "\n",
    "}\n",
    "\n",
    "items = []\n",
    "\n",
    "bhsa_df = df.copy()\n",
    "\n",
    "DSS_1Qisaa = DSS.copy()\n",
    "DSS_1Qisaa.scroll = \"1Qisaa\"\n",
    "previous_item = None\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    for source in (BHSA, DSS_1Qisaa):\n",
    "        item = row.to_dict()\n",
    "        args = ([row.book, row.chapter, row.verse], row.bhsa_lex, source)\n",
    "    \n",
    "        for name, function in columns_functions.items():\n",
    "            ob = function(*args)\n",
    "            if name in (\"complement\", \"preposition\"):\n",
    "                for i, element in enumerate(ob):\n",
    "                    item[f\"{name}_{i + 1}\"] = str(element)\n",
    "            else:\n",
    "                item[name] = str(ob)\n",
    "                \n",
    "        item[\"scroll\"] = source.get(\"scroll\", \"MT\")\n",
    "        items.append(item)\n",
    "        previous_item = item\n",
    "        previous_verse = get_verse(*args)\n",
    "\n",
    "new_dataframe = pd.DataFrame(items).fillna(\"\")\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e480d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = new_dataframe[[\"bhsa_lex\", \"book\", \"chapter\", \"verse\", \"scroll\", \"verb_heb\", \"verse_g_cons\",\"verse_heb\", \"verb_stem\", \"verb_tense\", \"verb_phrase\", \"verb_phrase_heb\", \"verb_clause\", \"verb_clause_heb\", \"subject\", \"subj_heb\", \"complement_1\", \"preposition_1\", \"complement_2\", \"preposition_2\", \"complement_3\", \"preposition_3\"]]\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe.to_csv(\"new_dataframe.csv\", sep=\";\", index=False, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d429c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all features of a node (here node 1030)\n",
    "Fall(1030)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
