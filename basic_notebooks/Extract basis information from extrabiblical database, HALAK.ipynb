{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ef015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d489f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric\n",
    "\n",
    "TF = Fabric(locations='C:/Users/zht702/Documents/extrabiblical/tf/0.2') # to be modified accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613eba99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api = TF.load('''\n",
    "    otype lex g_cons g_prs txt prs kind vs vt sp book chapter verse label language\n",
    "''')\n",
    "\n",
    "api.loadLog()\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences with BHSA:\n",
    "    # no opening brackets after verb lexemes\n",
    "    # the slash indicated the end of the lexeme of adjectives, nouns, proper nouns\n",
    "    # pronominal suff. are distinct words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74576a0f",
   "metadata": {},
   "source": [
    "Differences with BHSA:\n",
    "not [ after verbs\n",
    "and not slash after nouns, adjectives, proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815cb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in F.otype.s('book'):\n",
    "    chaps = L.d(book, 'chapter')\n",
    "    for chap in chaps:\n",
    "        print(T.bookName(book), F.chapter.v(chap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "for word in F.otype.s(\"word\"):\n",
    "    if F.lex.v(word) == \"HLK\":\n",
    "        n += 1\n",
    "        print(F.sp.v(word))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in F.otype.s(\"word\"):\n",
    "    print(F.lex.v(word), F.g_cons.v(word), F.sp.v(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([word for word in F.otype.s(\"word\") if F.lex.v(word) == \"HLK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c63331",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8228b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_info = {}\n",
    "\n",
    "for word in F.otype.s(\"word\"):\n",
    "    if F.lex.v(word) == \"HLK\":\n",
    "        book_node = L.u(word, \"book\")[0]\n",
    "        book = T.bookName(book_node)\n",
    "        chapter_node = L.u(word, \"chapter\")[0]\n",
    "        chapter = F.chapter.v(chapter_node)\n",
    "        verse_node = L.u(word, \"verse\")[0]\n",
    "        verse = F.verse.v(verse_node)\n",
    "        stem = F.vs.v(word)\n",
    "        verbal_tense = F.vt.v(word)\n",
    "        consonant_rep = F.g_cons.v(word)\n",
    "        language = F.language.v(word)   \n",
    "        features = [word, book, chapter, verse, book, stem, verbal_tense, consonant_rep, language]\n",
    "        halak_info[word] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745728d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(halak_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d114b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe = pd.DataFrame(halak_info).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8679fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.columns = [\"word\", \"book\", \"chapter\", \"verse\", \"scroll_name\", \"stem\", \"verbal_tense\", \"consonant_rep\", \"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b738302",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.to_csv(\"halak_data_xbib.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"halak_data_xbib.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd78e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.scroll_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.stem.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e2760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
