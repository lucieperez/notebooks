{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcee598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2306427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tf.app import use\n",
    "\n",
    "A = use(\"etcbc/bhsa\", hoist=globals())\n",
    "Fmt = F\n",
    "Lmt = L\n",
    "Tmt = T\n",
    "\n",
    "B = use(\"etcbc/dss\", checkout=\"clone\", version=\"1.8\", hoist=globals())\n",
    "Fdss = F\n",
    "Ldss = L\n",
    "Tdss = T\n",
    "\n",
    "# here we rename the functions F L and T so the DSS functions does not overwrite the BHSA functions\n",
    "# checkout=\"clone\" is to look for the data set in the folder ~/github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c55a9",
   "metadata": {},
   "source": [
    "What we are going to do now: for each occurrence of halak, we want to collect tf ID, book, chapter, verse, scroll name, stem, consonant rep. of the word, person number gender\n",
    "\n",
    "otype: specifies the object type that we are looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab4c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_info = {}\n",
    "\n",
    "book_names = set()\n",
    "\n",
    "for word in Fmt.otype.s(\"word\"):\n",
    "    if Fmt.lex.v(word) == \"HLK[\":\n",
    "        book, chapter, verse = Tmt.sectionFromNode(word)\n",
    "        book_names.add(book)\n",
    "        stem = Fmt.vs.v(word)\n",
    "        verbal_tense = Fmt.vt.v(word)\n",
    "        consonant_rep = Fmt.g_cons.v(word)\n",
    "        language = Fmt.language.v(word)\n",
    "        features = [word, book, str(chapter), str(verse), \"MT\", stem, verbal_tense, consonant_rep, language]\n",
    "        halak_info[word] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a6841",
   "metadata": {},
   "source": [
    "Structure in the DSS dataset: instead of book chapter verse being object type, they are features of word\n",
    "book is a feature: word level feature, give the biblical book where the word occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in Fdss.otype.s(\"word\"):\n",
    "    if Fdss.lex_etcbc.v(word) == \"HLK[\":\n",
    "        book = Fdss.book_etcbc.v(word)\n",
    "        chapter = Fdss.chapter.v(word)\n",
    "        verse = Fdss.verse.v(word)\n",
    "        scroll = Ldss.u(word, \"scroll\")[0]\n",
    "        scroll_name = Tdss.scrollName(scroll)\n",
    "        stem = Fdss.vs_etcbc.v(word)\n",
    "        verbal_tense = Fdss.vt_etcbc.v(word)\n",
    "        consonant_rep = Fdss.g_cons.v(word)\n",
    "        language = Fdss.lang_etcbc.v(word)\n",
    "        if book and book in book_names:   \n",
    "            features = [word, book, chapter, verse, scroll_name, stem, verbal_tense, consonant_rep, language]\n",
    "            halak_info[word] = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32734fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in Fdss.otype.s(\"word\"):\n",
    "    if Fdss.lex_etcbc.v(word) == \"HLK[\":\n",
    "        book = Fdss.book_etcbc.v(word)\n",
    "        chapter = Fdss.chapter.v(word)\n",
    "        verse = Fdss.verse.v(word)\n",
    "        print(word, book, chapter, verse)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(halak_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(halak_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1df590",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe = pd.DataFrame(halak_info).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.columns = [\"word\", \"book\", \"chapter\", \"verse\", \"scroll_name\", \"stem\", \"verbal_tense\", \"consonant_rep\", \"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a365250",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.stem.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(halak_dataframe.stem, halak_dataframe.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c918f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "halak_dataframe.to_csv(\"halak_data.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a533da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"halak_data.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be2e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
