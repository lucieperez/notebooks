{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8916c7f6-96f2-4b8e-bbc9-d567be0a14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4196aa-c407-4d8a-ae76-16587edd7a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4.1-mini\n",
      "Prompt: Give me a short story about bells and clocks in English.\n",
      "\n",
      "Story:\n",
      " In a quiet village nestled between rolling hills, the bells of the old church chimed every hour, echoing through the cobblestone streets. Nearby, the grand clock tower stood tall, its hands moving steadily, marking the passage of time for all to see.\n",
      "\n",
      "One day, the clock stopped. The villagers gathered, worried that time itself had paused. The bells fell silent, as if mourning the stillness. A young girl named Elara, curious and brave, climbed the tower to investigate. She discovered a tiny, forgotten gear jammed between the colossal cogs.\n",
      "\n",
      "With gentle hands, she freed the gear. The clock began to tick once more, and the bells burst into joyful song, ringing out over the village. From that day on, Elara was known as the Keeper of Time, the one who listened to the whispers of bells and clocks and kept their harmony alive.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to your file\n",
    "file_path = \"logs/2025-11-12_10-30-43_give_me_a_short_story_about_bells_and_clocks_in_english.json\"\n",
    "\n",
    "# Open and load the JSON content\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Access main fields\n",
    "print(\"Model:\", data[\"model\"])\n",
    "print(\"Prompt:\", data[\"prompt\"])\n",
    "print(\"\\nStory:\\n\", data[\"story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61f9d6c4-eb67-4632-b4cd-7276a318a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the interesting words from the prompt - function\n",
    "\n",
    "def extract_items_from_prompt(prompt: str):\n",
    "    \"\"\"\n",
    "    Extracts item1 and item2 from prompts of the form:\n",
    "    'Give me a short story about [item1] and [item2] in English.'\n",
    "    \"\"\"\n",
    "    pattern = r\"Give me a short story about (.*?) and (.*?) in English\\.\"\n",
    "    match = re.match(pattern, prompt.strip())\n",
    "    if match:\n",
    "        item1, item2 = match.groups()\n",
    "        return item1.strip(), item2.strip()\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "557050dc-944e-4d54-86d0-a1c14643af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find interesting logs - function\n",
    "\n",
    "def find_item_indices(data, item):\n",
    "    \"\"\"\n",
    "    Find all indices in data['token_positions'] where the token\n",
    "    matches 'item' (case-insensitive, stripped).\n",
    "    \"\"\"\n",
    "    item = item.strip().lower()\n",
    "    indices = []\n",
    "\n",
    "    for idx, pos in enumerate(data.get(\"token_positions\", [])):\n",
    "        for lp in pos.get(\"top_logprobs\", []):\n",
    "            token = (lp.get(\"token\") or \"\").strip().lower()\n",
    "            if token == item:\n",
    "                indices.append(idx)\n",
    "                break  # no need to check other top_logprobs at this position\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9968c44-ab86-456f-843f-73a3a0efdba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs_for_index(data, index):\n",
    "    \"\"\"\n",
    "    Return all log entries (token, logprob, probability)\n",
    "    for a given token position index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pos = data[\"token_positions\"][index]\n",
    "        return pos.get(\"top_logprobs\", [])\n",
    "    except (IndexError, KeyError, TypeError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b4c71ab-fe1b-44d3-90eb-a9ec2a91def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_logs_to_df(data, item):\n",
    "    \"\"\"\n",
    "    Finds all positions where 'item' appears and returns\n",
    "    a DataFrame with all candidate tokens, their logprobs, and probabilities.\n",
    "    \"\"\"\n",
    "    indices = find_item_indices(data, item)\n",
    "    rows = []\n",
    "\n",
    "    for idx in indices:\n",
    "        logs = get_logs_for_index(data, idx)\n",
    "        for lp in logs:\n",
    "            rows.append({\n",
    "                \"item\": item,\n",
    "                \"position\": idx,\n",
    "                \"token\": lp.get(\"token\"),\n",
    "                \"logprob\": lp.get(\"logprob\"),\n",
    "                \"probability\": lp.get(\"probability\"),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "292484bb-37d4-4f8e-a1a6-cccf0bab89e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "      <th>logprob</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bells</td>\n",
       "      <td>9</td>\n",
       "      <td>there</td>\n",
       "      <td>-0.733271</td>\n",
       "      <td>0.480335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bells</td>\n",
       "      <td>9</td>\n",
       "      <td>the</td>\n",
       "      <td>-0.858271</td>\n",
       "      <td>0.423894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item  position   token   logprob  probability\n",
       "0  bells         9   there -0.733271     0.480335\n",
       "1  bells         9     the -0.858271     0.423894"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item1, item2 = extract_items_from_prompt(data[\"prompt\"])\n",
    "df_item1 = item_logs_to_df(data, item1)\n",
    "df_item1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e3764d0-686d-4eb1-ac09-214e03ae089e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1336, 69935, 315, 61794]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-4-1-mini\")  # or your model\n",
    "enc.encode(\"whispers of bells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e8e4f93-5da3-45f4-84aa-2069521fd95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[166, 167]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_item_indices(data, \"whispers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f952522-786c-482e-8a4f-0185de997cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 10, 57, 61, 72, 134, 159, 166, 167, 169]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_item_indices(data, \"bells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18740e75-0d57-4b22-9342-a0397da8f423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
