{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bf4a09-9ab5-4300-bbfa-26311293f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tfob import TFOb,  get_dss, get_bhsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5eb9c08-a09f-4466-ba75-6f4099381cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Locating corpus resources ...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">app:</b> <span title=\"rv1.8.1=#gb112c161cfd21eae403d51a2733740d8743460e7 offline under C:/Users/University/text-fabric-data/github\">~/text-fabric-data/github/etcbc/bhsa/app</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv1.8.1=#gb112c161cfd21eae403d51a2733740d8743460e7 offline under C:/Users/University/text-fabric-data/github\">~/text-fabric-data/github/etcbc/bhsa/tf/2021</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv2.1=#gaba4367b49750089e4e4122415a77cac43bd97bc offline under C:/Users/University/text-fabric-data/github\">~/text-fabric-data/github/etcbc/phono/tf/2021</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv2.1=#gf45f6cc3c4f933dba6e649f49cdb14a40dcf333f offline under C:/Users/University/text-fabric-data/github\">~/text-fabric-data/github/etcbc/parallels/tf/2021</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv1.8.1=#gb112c161cfd21eae403d51a2733740d8743460e7 offline under C:/Users/University/text-fabric-data/github\">~/text-fabric-data/github/etcbc/bhsa/ner</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <b>TF:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"text-fabric api\">TF API 12.5.3</a>, <a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/blob/master/app\" title=\"etcbc/bhsa app\">etcbc/bhsa/app  v3</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br>\n",
       "            <b>Data:</b> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">etcbc - bhsa 2021</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/0_home\" title=\"etcbc - bhsa feature documentation\">Feature docs</a><br>\n",
       "            <details class=\"nodeinfo\"><summary><b>Node types</b></summary>\n",
       "<table class=\"nodeinfo\">\n",
       "    <tr>\n",
       "        <th>Name</th>\n",
       "        <th># of nodes</th>\n",
       "        <th># slots / node</th>\n",
       "        <th>% coverage</th>\n",
       "    </tr>\n",
       "\n",
       "<tr>\n",
       "    <th>book</th>\n",
       "    <td>39</td>\n",
       "    <td>10938.21</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>chapter</th>\n",
       "    <td>929</td>\n",
       "    <td>459.19</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>lex</th>\n",
       "    <td>9230</td>\n",
       "    <td>46.22</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>verse</th>\n",
       "    <td>23213</td>\n",
       "    <td>18.38</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>half_verse</th>\n",
       "    <td>45179</td>\n",
       "    <td>9.44</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>sentence</th>\n",
       "    <td>63717</td>\n",
       "    <td>6.70</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>sentence_atom</th>\n",
       "    <td>64514</td>\n",
       "    <td>6.61</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>clause</th>\n",
       "    <td>88131</td>\n",
       "    <td>4.84</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>clause_atom</th>\n",
       "    <td>90704</td>\n",
       "    <td>4.70</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>phrase</th>\n",
       "    <td>253203</td>\n",
       "    <td>1.68</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>phrase_atom</th>\n",
       "    <td>267532</td>\n",
       "    <td>1.59</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>subphrase</th>\n",
       "    <td>113850</td>\n",
       "    <td>1.42</td>\n",
       "    <td>38</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th><i>word</i></th>\n",
       "    <td>426590</td>\n",
       "    <td>1.00</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "</table></details>\n",
       "            <b>Sets:</b> no custom sets<br>\n",
       "            <b>Features:</b><br>\n",
       "<details><summary><b>Parallel Passages</b></summary>\n",
       "    <div class=\"fcorpus\">\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat edge\">\n",
       "<a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"~/text-fabric-data/github/etcbc/parallels/tf/2021/crossref.tf\">crossref</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> 🆗 links between similar passages</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "</details>\n",
       "\n",
       "<details><summary><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b></summary>\n",
       "    <div class=\"fcorpus\">\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/book.tf\">book</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ book name in Latin (Genesis; Numeri; Reges1; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book@ll\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/book@am.tf\">book@ll</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ book name in amharic (ኣማርኛ)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/chapter\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/chapter.tf\">chapter</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ chapter number (1; 2; 3; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/code\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/code.tf\">code</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ identifier of a clause atom relationship (0; 74; 367; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/det\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/det.tf\">det</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ determinedness of phrase(atom) (det; und; NA.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/domain\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/domain.tf\">domain</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ text type of clause (? (Unknown); N (narrative); D (discursive); Q (Quotation).)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/freq_lex\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/freq_lex.tf\">freq_lex</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ frequency of lexemes</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/function\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/function.tf\">function</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ syntactic function of phrase (Cmpl; Objc; Pred; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/g_cons.tf\">g_cons</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ word consonantal-transliterated (B R>CJT BR> >LHJM ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/g_cons_utf8.tf\">g_cons_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ word consonantal-Hebrew (ב ראשׁית ברא אלהים)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/g_lex.tf\">g_lex</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ lexeme pointed-transliterated (B.:- R;>CIJT B.@R@> >:ELOH ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/g_lex_utf8.tf\">g_lex_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ lexeme pointed-Hebrew (בְּ רֵאשִׁית בָּרָא אֱלֹה)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/g_word.tf\">g_word</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ word pointed-transliterated (B.:- R;>CI73JT B.@R@74> >:ELOHI92JM)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/g_word_utf8.tf\">g_word_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ word pointed-Hebrew (בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gloss\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/gloss.tf\">gloss</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> 🆗 english translation of lexeme (beginning create god(s))</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gn\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/gn.tf\">gn</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ grammatical gender (m; f; NA; unknown.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/label\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/label.tf\">label</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ (half-)verse label (half verses: A; B; C; verses:  GEN 01,02)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/language\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/language.tf\">language</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ of word or lexeme (Hebrew; Aramaic.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/lex.tf\">lex</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ lexeme consonantal-transliterated (B R>CJT/ BR>[ >LHJM/)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/lex_utf8.tf\">lex_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ lexeme consonantal-Hebrew (ב ראשׁית֜ ברא אלהים֜)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ls\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/ls.tf\">ls</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ lexical set, subclassification of part-of-speech (card; ques; mult)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nametype\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/nametype.tf\">nametype</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ⚠️ named entity type (pers; mens; gens; topo; ppde.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nme\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/nme.tf\">nme</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ nominal ending consonantal-transliterated (absent; n/a; JM, ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nu\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/nu.tf\">nu</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ grammatical number (sg; du; pl; NA; unknown.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/number\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/number.tf\">number</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ sequence number of an object within its context</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/otype\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/otype.tf\">otype</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> </span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pargr\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/pargr.tf\">pargr</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> 🆗 hierarchical paragraph number (1; 1.2; 1.2.3.4; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pdp\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/pdp.tf\">pdp</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ phrase dependent part-of-speech (art; verb; subs; nmpr, ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pfm\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/pfm.tf\">pfm</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ preformative consonantal-transliterated (absent; n/a; J, ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/prs.tf\">prs</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ pronominal suffix consonantal-transliterated (absent; n/a; W; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_gn\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/prs_gn.tf\">prs_gn</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ pronominal suffix gender (m; f; NA; unknown.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_nu\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/prs_nu.tf\">prs_nu</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ pronominal suffix number (sg; du; pl; NA; unknown.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_ps\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/prs_ps.tf\">prs_ps</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ pronominal suffix person (p1; p2; p3; NA; unknown.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ps\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/ps.tf\">ps</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ grammatical person (p1; p2; p3; NA; unknown.)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/qere.tf\">qere</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ word pointed-transliterated masoretic reading correction</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/qere_trailer.tf\">qere_trailer</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ interword material -pointed-transliterated (Masoretic correction)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/qere_trailer_utf8.tf\">qere_trailer_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ interword material -pointed-transliterated (Masoretic correction)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/qere_utf8.tf\">qere_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ word pointed-Hebrew masoretic reading correction</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rank_lex\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/rank_lex.tf\">rank_lex</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ ranking of lexemes based on freqnuecy</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rela\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/rela.tf\">rela</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ linguistic relation between clause/(sub)phrase(atom) (ADJ; MOD; ATR; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/sp\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/sp.tf\">sp</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ part-of-speech (art; verb; subs; nmpr, ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/st\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/st.tf\">st</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ state of a noun (a (absolute); c (construct); e (emphatic).)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/tab\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/tab.tf\">tab</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ clause atom: its level in the linguistic embedding</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/trailer.tf\">trailer</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ interword material pointed-transliterated (& 00 05 00_P ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/trailer_utf8.tf\">trailer_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ interword material pointed-Hebrew (־ ׃)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/txt\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/txt.tf\">txt</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ text type of clause and surrounding (repetion of ? N D Q as in feature domain)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/typ\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/typ.tf\">typ</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ clause/phrase(atom) type (VP; NP; Ellp; Ptcp; WayX)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/uvf\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/uvf.tf\">uvf</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ univalent final consonant consonantal-transliterated (absent; N; J; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbe\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/vbe.tf\">vbe</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ verbal ending consonantal-transliterated (n/a; W; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbs\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/vbs.tf\">vbs</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ root formation consonantal-transliterated (absent; n/a; H; ...)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/verse\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/verse.tf\">verse</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> ✅ verse number</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/voc_lex.tf\">voc_lex</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ vocalized lexeme pointed-transliterated (B.: R;>CIJT BR> >:ELOHIJM)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex_utf8\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/voc_lex_utf8.tf\">voc_lex_utf8</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ vocalized lexeme pointed-Hebrew (בְּ רֵאשִׁית ברא אֱלֹהִים)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vs\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/vs.tf\">vs</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ verbal stem (qal; piel; hif; apel; pael)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vt\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/vt.tf\">vt</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ✅ verbal tense (perf; impv; wayq; infc)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat edge\">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/mother\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/mother.tf\">mother</a>\n",
       "</div>\n",
       "<div class=\"fmono\">none</div>\n",
       "\n",
       "<span> ✅ linguistic dependency between textual objects</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat edge\">\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/oslots\" title=\"~/text-fabric-data/github/etcbc/bhsa/tf/2021/oslots.tf\">oslots</a>\n",
       "</div>\n",
       "<div class=\"fmono\">none</div>\n",
       "\n",
       "<span> </span>\n",
       "\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "</details>\n",
       "\n",
       "<details><summary><b>Phonetic Transcriptions</b></summary>\n",
       "    <div class=\"fcorpus\">\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/github/etcbc/phono/tf/2021/phono.tf\">phono</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> 🆗 phonological transcription (bᵊ rēšˌîṯ bārˈā ʔᵉlōhˈîm)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/github/etcbc/phono/tf/2021/phono_trailer.tf\">phono_trailer</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> 🆗 interword material in phonological transcription</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "</details>\n",
       "\n",
       "            <b>Settings:</b><br><details ><summary><b>specified</b></summary><ol><li><b>apiVersion</b>: <code>3</code></li><li><b>appName</b>: <code>etcbc/bhsa</code></li><li><b>appPath</b>: <code>C:/Users/University/text-fabric-data/github/etcbc/bhsa/app</code></li><li><b>commit</b>: <code>gb112c161cfd21eae403d51a2733740d8743460e7</code></li><li><b>css</b>: <code>''</code></li><li><details><summary><b>dataDisplay</b>:</summary><ul><li><details><summary><b>exampleSectionHtml</b>:</summary><code>&lt;code&gt;Genesis 1:1&lt;/code&gt; (use &lt;a href=\"https://github.com/{org}/{repo}/blob/master/tf/{version}/book%40en.tf\" target=\"_blank\"&gt;English book names&lt;/a&gt;)</code></details></li><li><details><summary><b>excludedFeatures</b>:</summary><ul><li><code>g_uvf_utf8</code></li><li><code>g_vbs</code></li><li><code>kq_hybrid</code></li><li><code>languageISO</code></li><li><code>g_nme</code></li><li><code>lex0</code></li><li><code>is_root</code></li><li><code>g_vbs_utf8</code></li><li><code>g_uvf</code></li><li><code>dist</code></li><li><code>root</code></li><li><code>suffix_person</code></li><li><code>g_vbe</code></li><li><code>dist_unit</code></li><li><code>suffix_number</code></li><li><code>distributional_parent</code></li><li><code>kq_hybrid_utf8</code></li><li><code>crossrefSET</code></li><li><code>instruction</code></li><li><code>g_prs</code></li><li><code>lexeme_count</code></li><li><code>rank_occ</code></li><li><code>g_pfm_utf8</code></li><li><code>freq_occ</code></li><li><code>crossrefLCS</code></li><li><code>functional_parent</code></li><li><code>g_pfm</code></li><li><code>g_nme_utf8</code></li><li><code>g_vbe_utf8</code></li><li><code>kind</code></li><li><code>g_prs_utf8</code></li><li><code>suffix_gender</code></li><li><code>mother_object_type</code></li></ul></details></li><li><details><summary><b>noneValues</b>:</summary><ul><li><code>absent</code></li><li><code>n/a</code></li><li><code>none</code></li><li><code>unknown</code></li><li><i>no value</i></li><li><code>NA</code></li></ul></details></li></ul></details></li><li><details><summary><b>docs</b>:</summary><ul><li><b>docBase</b>: <code>{docRoot}/{repo}</code></li><li><b>docExt</b>: <code>''</code></li><li><b>docPage</b>: <code>''</code></li><li><b>docRoot</b>: <code>https://{org}.github.io</code></li><li><b>featurePage</b>: <code>0_home</code></li></ul></details></li><li><b>interfaceDefaults</b>: <code>{}</code></li><li><b>isCompatible</b>: <code>True</code></li><li><b>local</b>: <code>local</code></li><li><details><summary><b>localDir</b>:</summary><code>C:/Users/University/text-fabric-data/github/etcbc/bhsa/_temp</code></details></li><li><details><summary><b>provenanceSpec</b>:</summary><ul><li><b>corpus</b>: <code>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</code></li><li><b>doi</b>: <code>10.5281/zenodo.1007624</code></li><li><b>extraData</b>: <code>ner</code></li><li><details><summary><b>moduleSpecs</b>:</summary><ul><li><details><summary>:</summary><ul><li><b>backend</b>: <i>no value</i></li><li><b>corpus</b>: <code>Phonetic Transcriptions</code></li><li><details><summary><b>docUrl</b>:</summary><code>https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb</code></details></li><li><b>doi</b>: <code>10.5281/zenodo.1007636</code></li><li><b>org</b>: <code>etcbc</code></li><li><b>relative</b>: <code>/tf</code></li><li><b>repo</b>: <code>phono</code></li></ul></details></li><li><details><summary>:</summary><ul><li><b>backend</b>: <i>no value</i></li><li><b>corpus</b>: <code>Parallel Passages</code></li><li><details><summary><b>docUrl</b>:</summary><code>https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb</code></details></li><li><b>doi</b>: <code>10.5281/zenodo.1007642</code></li><li><b>org</b>: <code>etcbc</code></li><li><b>relative</b>: <code>/tf</code></li><li><b>repo</b>: <code>parallels</code></li></ul></details></li></ul></details></li><li><b>org</b>: <code>etcbc</code></li><li><b>relative</b>: <code>/tf</code></li><li><b>repo</b>: <code>bhsa</code></li><li><b>version</b>: <code>2021</code></li><li><b>webBase</b>: <code>https://shebanq.ancient-data.org/hebrew</code></li><li><b>webHint</b>: <code>Show this on SHEBANQ</code></li><li><b>webLang</b>: <code>la</code></li><li><b>webLexId</b>: <code>True</code></li><li><details><summary><b>webUrl</b>:</summary><code>{webBase}/text?book=&lt;1&gt;&amp;chapter=&lt;2&gt;&amp;verse=&lt;3&gt;&amp;version={version}&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt</code></details></li><li><b>webUrlLex</b>: <code>{webBase}/word?version={version}&amp;id=&lt;lid&gt;</code></li></ul></details></li><li><b>release</b>: <code>v1.8.1</code></li><li><details><summary><b>typeDisplay</b>:</summary><ul><li><details><summary><b>clause</b>:</summary><ul><li><b>label</b>: <code>{typ} {rela}</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>clause_atom</b>:</summary><ul><li><b>hidden</b>: <code>True</code></li><li><b>label</b>: <code>{code}</code></li><li><b>level</b>: <code>1</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>half_verse</b>:</summary><ul><li><b>hidden</b>: <code>True</code></li><li><b>label</b>: <code>{label}</code></li><li><b>style</b>: <code>''</code></li><li><b>verselike</b>: <code>True</code></li></ul></details></li><li><details><summary><b>lex</b>:</summary><ul><li><b>featuresBare</b>: <code>gloss</code></li><li><b>label</b>: <code>{voc_lex_utf8}</code></li><li><b>lexOcc</b>: <code>word</code></li><li><b>style</b>: <code>orig</code></li><li><b>template</b>: <code>{voc_lex_utf8}</code></li></ul></details></li><li><details><summary><b>phrase</b>:</summary><ul><li><b>label</b>: <code>{typ} {function}</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>phrase_atom</b>:</summary><ul><li><b>hidden</b>: <code>True</code></li><li><b>label</b>: <code>{typ} {rela}</code></li><li><b>level</b>: <code>1</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>sentence</b>:</summary><ul><li><b>label</b>: <code>{number}</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>sentence_atom</b>:</summary><ul><li><b>hidden</b>: <code>True</code></li><li><b>label</b>: <code>{number}</code></li><li><b>level</b>: <code>1</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>subphrase</b>:</summary><ul><li><b>hidden</b>: <code>True</code></li><li><b>label</b>: <code>{number}</code></li><li><b>style</b>: <code>''</code></li></ul></details></li><li><details><summary><b>word</b>:</summary><ul><li><b>features</b>: <code>pdp vs vt</code></li><li><b>featuresBare</b>: <code>lex:gloss</code></li></ul></details></li></ul></details></li><li><b>writing</b>: <code>hbo</code></li></ol></details>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/browser/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/browser/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/browser/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/browser/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/browser/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/browser/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/browser/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/browser/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/browser/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".txtu.uga,.lex.uga {\n",
       "    font-family: sans-serif;\n",
       "    /*font-family: Noto Sans Ugaritic, sans-serif;*/\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".tfsechead {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--tfsechead);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".nde, a:link.nde {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".etf {\n",
       "    font-size: normal;\n",
       "    border-radius: 0.2rem;\n",
       "    border: 1pt solid white;\n",
       "    padding: 0 0.2rem ! important;\n",
       "    margin: 0 0.2rem ! important;\n",
       "}\n",
       ".etfx {\n",
       "    font-size: x-large;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       "#colormapplus, #colormapmin, .ecolormapmin {\n",
       "  font-weight: bold;\n",
       "  border-radius: 0.1rem;\n",
       "  background-color: #eeeeff;\n",
       "  padding: 0 1rem;\n",
       "  margin: 0 1rem;\n",
       "}\n",
       ".clr {\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "}\n",
       ".clmap,.eclmap {\n",
       "  padding: 0;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    /*display: inline-block;*/\n",
       "    display: inline-flex;\n",
       "    flex-flow: row wrap;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       "span.break {\n",
       "  flex-basis: 100%;\n",
       "  height: 0;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       "/* KEYBOARD */\n",
       ".ccoff {\n",
       "  background-color: inherit;\n",
       "}\n",
       ".ccon {\n",
       "  background-color: yellow ! important;\n",
       "}\n",
       ".ccon,.ccoff {\n",
       "  padding: 0.2rem;\n",
       "  margin: 0.2rem;\n",
       "  border: 0.1rem solid var(--letter-box-border);\n",
       "  border-radius: 0.1rem;\n",
       "}\n",
       ".ccline {\n",
       "  font-size: xx-large ! important;\n",
       "  font-weight: bold;\n",
       "  line-height: 2em ! important;\n",
       "}\n",
       "/* TF header */\n",
       "\n",
       "summary {\n",
       "  /* needed to override the normalize.less\n",
       "   * in the classical Jupyter Notebook\n",
       "   */\n",
       "  display: list-item ! important;\n",
       "}\n",
       "\n",
       ".fcorpus {\n",
       "  display: flex;\n",
       "  flex-flow: column nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "  overflow: auto;\n",
       "}\n",
       ".frow {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".fmeta {\n",
       "  display: flex;\n",
       "  flex-flow: column nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".fmetarow {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".fmetakey {\n",
       "  min-width: 8em;\n",
       "  font-family: monospace;\n",
       "}\n",
       ".fnamecat {\n",
       "  min-width: 8em;\n",
       "}\n",
       ".fnamecat.edge {\n",
       "  font-weight: bold;\n",
       "  font-style: italic;\n",
       "}\n",
       ".fmono {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--tfsechead:          hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "\t--letter-box-border:  hsla(  0,   0%,  80%, 0.5  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       ".ehl {\n",
       "  background-color: var(--ehl-strong);\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "\t--ehl-strong:       hsla(240, 100%,  70%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "globalThis.copyChar = (el, c) => {\n",
       "    for (const el of document.getElementsByClassName('ccon')) {\n",
       "        el.className = 'ccoff'\n",
       "    }\n",
       "    el.className = 'ccon'\n",
       "    navigator.clipboard.writeText(String.fromCharCode(c))\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>TF API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"doc\">N F E L T S C TF Fs Fall Es Eall Cs Call</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BHSA = get_bhsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1485965-0832-4b8f-96eb-e7f9dd59094f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457f5c69-9749-4b8e-ae8e-f2fd5de1e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"correct_verses.json\") as verses_file:\n",
    "    other_correct_verses = json.load(verses_file)\n",
    "\n",
    "with open(\"correct_clauses.json\") as clauses_file:\n",
    "    other_correct_clauses = json.load(clauses_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672aa10a-8417-44ad-8e49-be6d094c91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prose_books = [\n",
    "    \"Genesis\", \n",
    "    \"Exodus\",\n",
    "    \"Leviticus\",\n",
    "    \"Numbers\",\n",
    "    \"Deuteronomy\",\n",
    "    \"Joshua\",\n",
    "    \"Judges\",\n",
    "    \"1_Samuel\",\n",
    "    \"2_Samuel\",\n",
    "    \"1_Kings\",\n",
    "    \"2_Kings\",\n",
    "    \"Jonah\",\n",
    "    \"Ruth\",\n",
    "    \"Esther\",\n",
    "    \"Daniel\",\n",
    "    \"Ezra\",\n",
    "    \"Nehemiah\",\n",
    "    \"1_Chronicles\",\n",
    "    \"2_Chronicles\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21fd470-8609-47c7-b096-49998f76705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "verses_bhsa = TFOb.all(\"verse\", BHSA).filter_in(book=prose_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a26fd9-0638-42f5-b8c8-2dc28b2c3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a list with the Hebrew Alphabet (including final letters and space)\n",
    "\n",
    "hebrew_alphabet = [\n",
    "    'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', \n",
    "    'י', 'כ', 'ך', 'ל', 'מ', 'ם', 'נ', 'ן', 'ס', \n",
    "    'ע', 'פ', 'ף', 'צ', 'ץ', 'ק', 'ר', 'ש', 'ת',\n",
    "    ' ',\n",
    "]\n",
    "\n",
    "# Create a set for faster results\n",
    "\n",
    "heb_alph_set = set(hebrew_alphabet)\n",
    "\n",
    "def heb_without_diac(clause):\n",
    "    \"\"\"Clean a string in Hebrew script from diactrics.\"\"\"\n",
    "    clause = str(clause.text)\n",
    "    filtered_signs = [sign for sign in clause if sign in heb_alph_set]\n",
    "    cleaned_clause = \"\".join(filtered_signs)\n",
    "    return cleaned_clause\n",
    "    \n",
    "\n",
    "def extract_result(line):\n",
    "    return line[\"verse\"].split(\":\")[1].strip(), line[\"parsed_clauses\"].replace(\"```\", \"\").replace(\"json\", \"\").replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae498d5-95ea-494c-8cab-ce3d7a8f8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "verses_bhsa_dict = {heb_without_diac(verse).strip(): verse for verse in verses_bhsa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f06b9b-4bf4-4c89-9270-6f95468e7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_path = \"data/verses_clauses_dict.json\"\n",
    "model_path = \"data/fine_tuning_datasets/basic_models_outputs/output_validation_large_gpt4o_mini.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94ff6d32-8dd2-4b7b-a24f-2907dd27bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"GPT-4o mini\"\n",
    "fine_tuned_status = \"no\"\n",
    "training_dataset_size = \"large\"\n",
    "temperature = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "76392aa9-8abc-4694-845c-626c8d51094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "def load_gold_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_model_output_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "# --- 2. Embedded clause detection --- (Olivier Lauzanne)\n",
    "\n",
    "def is_sub_list(a, b):\n",
    "    \"\"\"Check if a is a sublist of b. O. Lauzanne\"\"\"\n",
    "    for i in range(len(b)):\n",
    "        if b[i:i + len(a)] == a:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def find_cut_clauses(verse):\n",
    "    # Get the TFOb object of the verse and clauses\n",
    "    verse = verses_bhsa_dict[verse]\n",
    "    clauses = verse.to_clauses\n",
    "\n",
    "    return [heb_without_diac(clause).strip() for clause in clauses if not is_sub_list(clause.to_words.ids, verse.to_words.ids)]    \n",
    "            \n",
    "    \n",
    "def find_embedded_clauses(verse, debug=False):\n",
    "    # Get the TFOb object of the verse and clauses\n",
    "    verse = verses_bhsa_dict[verse]\n",
    "    clauses = verse.to_clauses\n",
    "\n",
    "    cut_clauses = [clause for clause in clauses if not is_sub_list(clause.to_words.ids, verse.to_words.ids)]\n",
    "    if debug:\n",
    "        for cut_clause in cut_clauses:\n",
    "            print(cut_clause)\n",
    "            print(cut_clause.text)\n",
    "        \n",
    "    word_to_clause = {}\n",
    "    for clause in clauses:\n",
    "        for word in clause.to_words.ids:\n",
    "            word_to_clause[word] = clause\n",
    "\n",
    "    \n",
    "    embedded_clauses = set()\n",
    "    \n",
    "    for cut_clause in cut_clauses:\n",
    "\n",
    "        first_word_index = verse.to_words.ids.index(cut_clause.to_words.ids[0])\n",
    "        last_word_index = verse.to_words.ids.index(cut_clause.to_words.ids[-1])\n",
    "\n",
    "        words = verse.to_words.ids[first_word_index + 1:last_word_index]\n",
    "\n",
    "        for word in words:\n",
    "            if word not in cut_clause.to_words.ids:\n",
    "                embedded_clauses.add(heb_without_diac(word_to_clause[word]).strip())\n",
    "  \n",
    "    return embedded_clauses\n",
    "\n",
    "# Comparison\n",
    "\n",
    "correct_verses_local = []\n",
    "correct_clauses_local = []\n",
    "\n",
    "def compare_model_to_gold(gold_dict, model_output_list):\n",
    "    results = []\n",
    "\n",
    "    # Index model output by cleaned verse\n",
    "    n_bad_json = 0\n",
    "    \n",
    "    model_map = {}\n",
    "    for i, entry in enumerate(model_output_list):\n",
    "        verse, raw_clauses = extract_result(entry)\n",
    "        \n",
    "        #verse = entry[\"verse\"].replace(\"Parse this verse:\", \"\").strip()\n",
    "        try:\n",
    "            #predicted = json.loads(entry[\"parsed_clauses\"])\n",
    "            predicted = json.loads(raw_clauses)\n",
    "            model_map[verse] = (i, [c.strip() for c in predicted])\n",
    "        except json.JSONDecodeError:\n",
    "            model_map[verse] = (i, [])\n",
    "            n_bad_json += 1\n",
    "            \n",
    "    print(\"Number of bad JSON: \", n_bad_json)\n",
    "\n",
    "    for verse, info in gold_dict.items():\n",
    "        gold_clauses = [c.strip() for c in info[\"clauses\"]]\n",
    "        #print(gold_clauses)\n",
    "        complexity = info[\"complexity\"]\n",
    "        embedded = find_embedded_clauses(verse)\n",
    "        cut_clauses = find_cut_clauses(verse)\n",
    "\n",
    "        if verse not in model_map:\n",
    "            continue  # model never predicted on this verse\n",
    "\n",
    "        row_idx, predicted_clauses = model_map[verse]\n",
    "\n",
    "        matched = [c for c in predicted_clauses if c in gold_clauses]\n",
    "\n",
    "        correct_clauses_local.extend(matched)\n",
    "        \n",
    "        missed = [c for c in gold_clauses if c not in predicted_clauses]\n",
    "        embedded_found = [c for c in predicted_clauses if c in embedded]\n",
    "        embedded_missed = [c for c in embedded if c not in predicted_clauses]\n",
    "        cut_clauses_found = [c for c in predicted_clauses if c in cut_clauses]\n",
    "        cut_clauses_missed = [c for c in cut_clauses if c not in predicted_clauses]\n",
    "        non_embedded = [c for c in gold_clauses if c not in embedded]\n",
    "        non_embedded_found = [c for c in predicted_clauses if c in non_embedded]\n",
    "        non_cut_clauses = [c for c in gold_clauses if c not in cut_clauses]\n",
    "        non_cut_clauses_found = [c for c in predicted_clauses if c in non_cut_clauses]\n",
    "\n",
    "        other_clauses = [c for c in gold_clauses if c not in cut_clauses and c not in embedded]\n",
    "        other_clauses_found = [c for c in predicted_clauses if c in other_clauses]\n",
    "        \n",
    "        complete_verse_correct = int(predicted_clauses == gold_clauses)\n",
    "        if complete_verse_correct:\n",
    "            correct_verses_local.append(verse)\n",
    "        \n",
    "        results.append({\n",
    "            \"row\": row_idx,\n",
    "            \"verse\": verse,\n",
    "            \"complexity\": complexity,\n",
    "\n",
    "            # Clause info\n",
    "\n",
    "            \"gold_clauses\": gold_clauses,\n",
    "            \"predicted_clauses\": predicted_clauses,\n",
    "            \"matched_clauses\": matched,\n",
    "            \"missed_clauses\": missed,\n",
    "        \n",
    "            # Counts\n",
    "            \"total_gold\": len(gold_clauses),\n",
    "            \"matched_count\": len(matched),\n",
    "            \"missed_count\": len(missed),\n",
    "            \"embedded_count\": len(embedded),\n",
    "            \"embedded_found_count\": len(embedded_found),\n",
    "            \"embedded_missed_count\": len(embedded_missed),\n",
    "            \"cut_clauses_count\": len(cut_clauses),\n",
    "            \"cut_clauses_found\": len(cut_clauses_found),\n",
    "            \"cut_clauses_missed\": len(cut_clauses_missed),\n",
    "            \"non_embedded_count\": len(non_embedded),\n",
    "            \"non_embedded_found\": len(non_embedded_found),\n",
    "            \"non_cut_clauses_count\": len(non_cut_clauses),\n",
    "            \"non_cut_clauses_found\": len(non_cut_clauses_found),\n",
    "            \"other_clauses_count\": len(other_clauses),\n",
    "            \"other_clauses_found\": len(other_clauses_found),\n",
    "            \"complete_verse_correct\": complete_verse_correct,\n",
    "        \n",
    "            # Optional: keep raw lists for reference/debugging\n",
    "            # Comment these out if not needed\n",
    "\n",
    "            \n",
    "            \"embedded_clauses\": embedded,\n",
    "            \"embedded_found_list\": embedded_found,\n",
    "            \"embedded_missed_list\": embedded_missed\n",
    "        })\n",
    "\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "17a81a47-e7eb-45ea-9ec3-c35fa595d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dict = load_gold_json(gold_path)\n",
    "model_output = load_model_output_jsonl(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1121c65-5820-472c-9a9a-55910d72c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad JSON:  0\n"
     ]
    }
   ],
   "source": [
    "df_results = compare_model_to_gold(gold_dict, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09c13dec-6a22-4057-8bad-546875faf448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "645770af-9ba5-49f8-8a64-a862911bc375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if the list of clauses returned by the model add / remove words from the original verse given.\n",
    "\n",
    "def clean_text(text, hebrew_alphabet):\n",
    "    # Keep only Hebrew letters and normalize spaces\n",
    "    cleaned = ''.join([c if c in hebrew_alphabet else ' ' for c in text])\n",
    "    return re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "\n",
    "identical_verses = 0 # perfect string-level matches between the original_verse and the reconstructed_clean version.\n",
    "verses = 0\n",
    "same_as_original_words = 0 # semantically similar verses based on word content, even if the full strings don't match exactly\n",
    "    \n",
    "for item in model_output:\n",
    "    original_verse = item[\"verse\"].split(\": \", 1)[1]\n",
    "    \n",
    "    clause_string = item[\"parsed_clauses\"]\n",
    "    clause_string = clause_string.strip()[1:-1]\n",
    "    clauses = [clause.strip().strip('\"') for clause in clause_string.split('\", \"')]\n",
    "    \n",
    "    reconstructed_verse = ''.join(clauses)\n",
    "\n",
    "    stripped_clauses = [clause.strip() for clause in clauses]\n",
    "    reconstructed_verse = ' '.join(stripped_clauses)\n",
    "\n",
    "    reconstructed_clean = clean_text(reconstructed_verse, hebrew_alphabet)\n",
    "\n",
    "    if original_verse != reconstructed_clean:\n",
    "        #print(\"❌ Different verse:\")\n",
    "        #print(\"Original:     \", original_verse)\n",
    "        #print(\"Reconstructed:\", reconstructed_clean)\n",
    "\n",
    "        original_words = set(original_verse.split())\n",
    "        reconstructed_words = set(reconstructed_clean.split())\n",
    "        \n",
    "        if original_words == reconstructed_words or \"\".join(sorted(original_words)) == \"\".join(sorted(reconstructed_words)):\n",
    "            same_as_original_words += 1\n",
    "            #print(\"✅ Same words\")\n",
    "            #print(\"\\n\")\n",
    "            \n",
    "        elif ''.join(sorted(''.join(original_words))) == ''.join(sorted(''.join(reconstructed_words))):\n",
    "            same_as_original_words += 1\n",
    "            #print(\"✅ Same characters when words are joined\")\n",
    "            #print(\"\\n\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\")\n",
    "            #print(\"❌ Different words\")\n",
    "            #print(\"Only in original:     \", original_words - reconstructed_words)\n",
    "            #print(\"Only in reconstructed:\", reconstructed_words - original_words)\n",
    "            #print(\"\\n\")\n",
    "    else:\n",
    "        identical_verses += 1\n",
    "        \n",
    "        original_words = set(original_verse.split())\n",
    "        reconstructed_words = set(reconstructed_clean.split())\n",
    "        \n",
    "        if original_words == reconstructed_words:\n",
    "            \n",
    "            same_as_original_words += 1\n",
    "            #print(\"✅ Same words\")\n",
    "            #print(\"\\n\")\n",
    "        \n",
    "        elif ''.join(sorted(''.join(original_words))) == ''.join(sorted(''.join(reconstructed_words))):\n",
    "            same_as_original_words += 1\n",
    "            #print(\"✅ Same characters when words are joined\")\n",
    "            #print(\"\\n\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\")\n",
    "            #print(\"❌ Different words\")\n",
    "            #print(\"Only in original:     \", original_words - reconstructed_words)\n",
    "            #print(\"Only in reconstructed:\", reconstructed_words - original_words)\n",
    "            #print(\"\\n\")\n",
    "            \n",
    "        #print(\"✅ Match:\")\n",
    "        #print(\"Original:     \", original_verse)\n",
    "        #print(\"Reconstructed:\", reconstructed_clean)\n",
    "\n",
    "  \n",
    "    verses += 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bcc5ea6-b1bd-46ee-9f7f-bbbd758a104e",
   "metadata": {},
   "source": [
    "# initialise results_df for verses and words restitution (Input/Output consistency) ONLY ONCE\n",
    "\n",
    "df_input_output = pd.DataFrame(columns=[\n",
    "    \"model\",\n",
    "    \"temperature\",\n",
    "    \"fine_tuned\",\n",
    "    \"training_dataset_size\",\n",
    "    \"percentage_exact_restitution\",\n",
    "    \"percentage_exact_words_restitution\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "794b9c66-a2bd-4215-9f56-df950210eac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>fine_tuned</th>\n",
       "      <th>training_dataset_size</th>\n",
       "      <th>percentage_exact_restitution</th>\n",
       "      <th>percentage_exact_words_restitution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>small</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>medium</td>\n",
       "      <td>92.300000</td>\n",
       "      <td>99.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>large</td>\n",
       "      <td>89.067278</td>\n",
       "      <td>98.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>small</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>medium</td>\n",
       "      <td>94.400000</td>\n",
       "      <td>98.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>large</td>\n",
       "      <td>90.902141</td>\n",
       "      <td>98.776758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>89.100000</td>\n",
       "      <td>89.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>large</td>\n",
       "      <td>89.067278</td>\n",
       "      <td>89.181957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>81.500000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>79.100000</td>\n",
       "      <td>88.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>large</td>\n",
       "      <td>78.402141</td>\n",
       "      <td>87.232416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model temperature fine_tuned training_dataset_size  \\\n",
       "0        GPT-4o           0        yes                 small   \n",
       "1        GPT-4o           0        yes                medium   \n",
       "2        GPT-4o           0        yes                 large   \n",
       "3   GPT-4o mini           0        yes                 small   \n",
       "4   GPT-4o mini           0        yes                medium   \n",
       "5   GPT-4o mini           0        yes                 large   \n",
       "6        GPT-4o           0         no                 small   \n",
       "7        GPT-4o           0         no                medium   \n",
       "8        GPT-4o           0         no                 large   \n",
       "9   GPT-4o mini           0         no                 small   \n",
       "10  GPT-4o mini           0         no                medium   \n",
       "11  GPT-4o mini           0         no                 large   \n",
       "\n",
       "    percentage_exact_restitution  percentage_exact_words_restitution  \n",
       "0                      94.500000                           99.000000  \n",
       "1                      92.300000                           99.200000  \n",
       "2                      89.067278                           98.967890  \n",
       "3                      95.000000                           99.000000  \n",
       "4                      94.400000                           98.900000  \n",
       "5                      90.902141                           98.776758  \n",
       "6                      87.000000                           87.000000  \n",
       "7                      89.100000                           89.200000  \n",
       "8                      89.067278                           89.181957  \n",
       "9                      81.500000                           91.000000  \n",
       "10                     79.100000                           88.800000  \n",
       "11                     78.402141                           87.232416  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute metrics\n",
    "percentage_exact_restitution = (identical_verses / verses) * 100\n",
    "percentage_exact_words_restitution = (same_as_original_words / verses) * 100\n",
    "\n",
    "# Add first result to the DataFrame\n",
    "df_input_output = pd.concat([\n",
    "    df_input_output,\n",
    "    pd.DataFrame([{\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"fine_tuned\": fine_tuned_status,\n",
    "        \"training_dataset_size\": training_dataset_size,\n",
    "        \"percentage_exact_restitution\": percentage_exact_restitution,\n",
    "        \"percentage_exact_words_restitution\": percentage_exact_words_restitution\n",
    "    }])\n",
    "], ignore_index=True)\n",
    "\n",
    "# show df\n",
    "df_input_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7a4bd9b1-dce6-4a78-99c7-e596836dbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_input_output.to_csv(\"data/input_output_consistency.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1dbf9a81-9920-44d2-b965-c4f848de74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall counts\n",
    "total_clauses = df_results[\"total_gold\"].sum()\n",
    "total_found = df_results[\"matched_count\"].sum()\n",
    "total_cut_clauses = df_results[\"cut_clauses_count\"].sum()\n",
    "\n",
    "# Embedded\n",
    "total_embedded = df_results[\"embedded_count\"].sum()\n",
    "found_embedded = df_results[\"embedded_found_count\"].sum()\n",
    "\n",
    "# Non-embedded\n",
    "total_non_embedded = df_results[\"non_embedded_count\"].sum()\n",
    "found_non_embedded = df_results[\"non_embedded_found\"].sum()\n",
    "\n",
    "# Cut Clauses\n",
    "total_cut_clauses = df_results[\"cut_clauses_count\"].sum()\n",
    "found_cut_clauses = df_results[\"cut_clauses_found\"].sum()\n",
    "\n",
    "# Cut Clauses\n",
    "total_other_clauses = df_results[\"other_clauses_count\"].sum()\n",
    "found_other_clauses = df_results[\"other_clauses_found\"].sum()\n",
    "\n",
    "# Non Cut Clauses\n",
    "total_non_cut_clauses = df_results[\"non_cut_clauses_count\"].sum()\n",
    "found_non_cut_clauses = df_results[\"non_cut_clauses_found\"].sum()\n",
    "\n",
    "# Full verse match\n",
    "total_verses = len(df_results)\n",
    "correct_verses = df_results[\"complete_verse_correct\"].sum()\n",
    "\n",
    "# By complexity\n",
    "simple_df = df_results[df_results[\"embedded_count\"] == 0]\n",
    "complex_df = df_results[df_results[\"embedded_count\"] != 0]\n",
    "\n",
    "simple_correct = simple_df[\"complete_verse_correct\"].sum()\n",
    "complex_correct = complex_df[\"complete_verse_correct\"].sum()\n",
    "\n",
    "total_simple_clauses = simple_df[\"total_gold\"].sum()\n",
    "total_simple_found = simple_df[\"matched_count\"].sum()\n",
    "\n",
    "total_complex_clauses = complex_df[\"total_gold\"].sum()\n",
    "total_complex_found = complex_df[\"matched_count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ecbaac96-f3af-4736-9d71-4d9b3a8f070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of your stats\n",
    "stats_dict = {\n",
    "    \"model\": model,\n",
    "    \"dataset_size\": training_dataset_size,\n",
    "    \"temperature\": temperature,\n",
    "    \"fine_tuned\": fine_tuned_status,\n",
    "    \"total_clauses\": total_clauses,\n",
    "    \"total_found\": total_found,\n",
    "    \"total_cut_clauses\": total_cut_clauses,\n",
    "    \"total_embedded\": total_embedded,\n",
    "    \"found_embedded\": found_embedded,\n",
    "    \"total_non_embedded\": total_non_embedded,\n",
    "    \"found_non_embedded\": found_non_embedded,\n",
    "    \"found_cut_clauses\": found_cut_clauses,\n",
    "    \"total_other_clauses\": total_other_clauses,\n",
    "    \"found_other_clauses\": found_other_clauses,\n",
    "    \"total_non_cut_clauses\": total_non_cut_clauses,\n",
    "    \"found_non_cut_clauses\": found_non_cut_clauses,\n",
    "    \"total_verses\": total_verses,\n",
    "    \"correct_verses\": correct_verses,\n",
    "    \"simple_correct\": simple_correct,\n",
    "    \"complex_correct\": complex_correct,\n",
    "    \"total_simple_clauses\": total_simple_clauses,\n",
    "    \"total_simple_found\": total_simple_found,\n",
    "    \"total_complex_clauses\": total_complex_clauses,\n",
    "    \"total_complex_found\": total_complex_found\n",
    "}\n",
    "\n",
    "# Create df_stats from the dictionary\n",
    "#df_stats = pd.DataFrame([stats_dict])\n",
    "\n",
    "# Add new data as a new row to the df_stats\n",
    "#df_stats = pd.concat([df_stats, pd.DataFrame([stats_dict])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa83fc-53f7-42ea-825c-57740d8f4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_stats.to_csv(\"data/all_models_metrics_for_paper.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90c1ab-94db-485a-998c-caea08a0735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percentage of correctly returned verses: {identical_verses}/{verses}\", identical_verses/verses * 100, \"%\")\n",
    "print(f\"Percentage of correct set of words: {same_as_original_words}/{verses}\", same_as_original_words/verses * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ab86d-128a-4ef4-886b-cfe8563b28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print Results ---\n",
    "print(\"📊 Accuracy Summary\\n\")\n",
    "\n",
    "print(f\"Total gold clauses: {total_clauses}\")\n",
    "print(f\"Correctly predicted clauses: {total_found}\")\n",
    "print(f\"✅ Overall clause accuracy: {total_found / total_clauses:.2%}\\n\")\n",
    "\n",
    "print(f\"Total gold clauses in simple verses: {total_simple_clauses}\")\n",
    "print(f\"Correctly predicted clauses in simple verses: {total_simple_found}\")\n",
    "print(f\"✅ Clause accuracy in simple verses: {total_simple_found / total_simple_clauses:.2%}\\n\")\n",
    "\n",
    "print(f\"Total gold clauses in complex verses: {total_complex_clauses}\")\n",
    "print(f\"Correctly predicted clauses in complex verses: {total_complex_found}\")\n",
    "print(f\"✅ Clause accuracy in complex verses: {total_complex_found / total_complex_clauses:.2%}\\n\")\n",
    "\n",
    "print(f\"Embedded clauses in gold: {total_embedded}\")\n",
    "print(f\"Found embedded clauses: {found_embedded}\")\n",
    "print(f\"✅ Embedded clause accuracy: {found_embedded / total_embedded:.2%}\" if total_embedded else \"⚠️ No embedded clauses.\\n\")\n",
    "\n",
    "#print(f\"\\nNon-embedded clauses in gold: {total_non_embedded}\")\n",
    "#print(f\"Found non-embedded clauses: {found_non_embedded}\")\n",
    "#print(f\"✅ Non-embedded clause accuracy: {found_non_embedded / total_non_embedded:.2%}\" if total_non_embedded else \"⚠️ No non-embedded clauses.\\n\")\n",
    "\n",
    "print(f\"\\nCut clauses in gold: {total_cut_clauses}\")\n",
    "print(f\"Found cut clauses: {found_cut_clauses}\")\n",
    "print(f\"✅ Cut clause accuracy: {found_cut_clauses / total_cut_clauses:.2%}\" if total_cut_clauses else \"⚠️ No cut clauses.\\n\")\n",
    "\n",
    "print(f\"\\nOther clauses in gold: {total_other_clauses}\")\n",
    "print(f\"Found other clauses: {found_other_clauses}\")\n",
    "print(f\"✅ Other clause accuracy: {found_other_clauses / total_other_clauses:.2%}\" if total_other_clauses else \"⚠️ No other clauses.\\n\")\n",
    "\n",
    "#print(f\"\\nNon cut clauses in gold: {total_non_cut_clauses}\")\n",
    "#print(f\"Found non cut clauses: {found_non_cut_clauses}\")\n",
    "#print(f\"✅ Non cut clause accuracy: {found_non_cut_clauses / total_non_cut_clauses:.2%}\" if total_non_cut_clauses else \"⚠️ No non cut clauses.\\n\")\n",
    "\n",
    "print(f\"\\nComplete verse parses: {correct_verses} / {total_verses}\")\n",
    "print(f\"✅ Full verse accuracy: {correct_verses / total_verses:.2%}\")\n",
    "\n",
    "print(f\"\\nSimple verse parses correct: {simple_correct} / {len(simple_df)}\")\n",
    "print(f\"✅ Accuracy on simple verses: {simple_correct / len(simple_df):.2%}\" if len(simple_df) else \"⚠️ No simple verses.\")\n",
    "\n",
    "print(f\"\\nComplex verse parses correct: {complex_correct} / {len(complex_df)}\")\n",
    "print(f\"✅ Accuracy on complex verses: {complex_correct / len(complex_df):.2%}\" if len(complex_df) else \"⚠️ No complex verses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2980f16-1949-4961-938d-1a53b25ca75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_clause_match(row):\n",
    "    return set(row[\"predicted_clauses\"]) == set(row[\"gold_clauses\"])\n",
    "\n",
    "df_results[\"full_clause_match\"] = df_results.apply(full_clause_match, axis=1)\n",
    "\n",
    "simple_full_correct = df_results[df_results[\"embedded_count\"] == 0][\"full_clause_match\"].sum()\n",
    "complex_full_correct = df_results[df_results[\"embedded_count\"] != 0][\"full_clause_match\"].sum()\n",
    "\n",
    "print(\"\\n📘 Fully Correct Clause Identification by Complexity (Order-insensitive)\")\n",
    "print(f\"🔹 Simple: {simple_full_correct} / {len(simple_df)} → Accuracy: {simple_full_correct / len(simple_df):.2%}\" if len(simple_df) else \"🔹 No simple verses.\")\n",
    "print(f\"🔸 Complex: {complex_full_correct} / {len(complex_df)} → Accuracy: {complex_full_correct / len(complex_df):.2%}\" if len(complex_df) else \"🔸 No complex verses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3acef-718a-4c86-a3e0-dc14d95009d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"ordered_full_match\"] = df_results.apply(\n",
    "    lambda row: row[\"predicted_clauses\"] == row[\"gold_clauses\"], axis=1\n",
    ")\n",
    "\n",
    "simple_ordered_correct = df_results[df_results[\"embedded_count\"] == 0][\"ordered_full_match\"].sum()\n",
    "complex_ordered_correct = df_results[df_results[\"embedded_count\"] != 0][\"ordered_full_match\"].sum()\n",
    "\n",
    "print(\"\\n📘 Fully Correct Clause Identification by Complexity (Order-sensitive)\")\n",
    "print(f\"🔹 Simple: {simple_ordered_correct} / {len(simple_df)} → Accuracy: {simple_ordered_correct / len(simple_df):.2%}\" if len(simple_df) else \"🔹 No simple verses.\")\n",
    "print(f\"🔸 Complex: {complex_ordered_correct} / {len(complex_df)} → Accuracy: {complex_ordered_correct / len(complex_df):.2%}\" if len(complex_df) else \"🔸 No complex verses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908cc10-dab4-4004-adea-ed91a5c8a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(row):\n",
    "    predicted = row[\"predicted_clauses\"]\n",
    "    if not predicted:\n",
    "        return None\n",
    "    gold = row[\"gold_clauses\"]\n",
    "    matched = [cl for cl in predicted if cl in gold]\n",
    "    return len(matched) / len(predicted)\n",
    "\n",
    "df_results[\"precision\"] = df_results.apply(compute_precision, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2478a06-7752-4268-8304-e3571b57a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_df = df_results[df_results[\"embedded_count\"] == 0]\n",
    "complex_df = df_results[df_results[\"embedded_count\"] != 0]\n",
    "\n",
    "simple_precision = simple_df[\"precision\"].dropna().mean()\n",
    "complex_precision = complex_df[\"precision\"].dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878adb2a-1e9d-469a-8d01-0d161a7b6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_precision_summary(df, label):\n",
    "    df = df.copy()\n",
    "    df = df[~df[\"precision\"].isna()]\n",
    "    n_verses = len(df)\n",
    "    avg_precision = df[\"precision\"].mean()\n",
    "    total_predicted = df[\"predicted_clauses\"].apply(len).sum()  # still list-based\n",
    "    total_matched = df[\"matched_count\"].sum()  # now scalar-based\n",
    "\n",
    "    print(f\"\\n📘 Precision Summary – {label}\")\n",
    "    print(f\"Verses evaluated: {n_verses}\")\n",
    "    print(f\"Total predicted clauses: {total_predicted}\")\n",
    "    print(f\"Total correct predicted clauses: {total_matched}\")\n",
    "    print(f\"📐 Average per-verse precision: {avg_precision:.2%}\")\n",
    "    print(f\"📐 Overall clause-level precision: {total_matched / total_predicted:.2%}\" if total_predicted else \"⚠️ No predictions made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26814aa5-5ec9-4572-89aa-53d427f2ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_precision_summary(simple_df, \"Simple\")\n",
    "detailed_precision_summary(complex_df, \"Complex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7acc64-b605-4f60-af48-667fb2c3d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters\n",
    "total_predicted = df_results[\"predicted_clauses\"].apply(len).sum()\n",
    "total_matched = df_results[\"matched_count\"].sum()\n",
    "\n",
    "predicted_embedded = 0\n",
    "matched_embedded = 0\n",
    "predicted_non_embedded = 0\n",
    "matched_non_embedded = 0\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    gold = set(row[\"gold_clauses\"])\n",
    "    embedded = set(row[\"embedded_clauses\"])\n",
    "    predicted = set(row[\"predicted_clauses\"])\n",
    "\n",
    "    for clause in predicted:\n",
    "        if clause in embedded:\n",
    "            predicted_embedded += 1\n",
    "            if clause in gold:\n",
    "                matched_embedded += 1\n",
    "        else:\n",
    "            predicted_non_embedded += 1\n",
    "            if clause in gold:\n",
    "                matched_non_embedded += 1\n",
    "\n",
    "# Compute precisions\n",
    "global_precision = total_matched / total_predicted if total_predicted else None\n",
    "embedded_precision = matched_embedded / predicted_embedded if predicted_embedded else None\n",
    "non_embedded_precision = matched_non_embedded / predicted_non_embedded if predicted_non_embedded else None\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📘 Clause-Level Precision by Clause Type\")\n",
    "\n",
    "print(f\"🌐 Global precision: {total_matched} / {total_predicted} → {global_precision:.2%}\" if global_precision is not None else \"🌐 No predictions made.\")\n",
    "\n",
    "print(f\"🔸 Embedded precision: {matched_embedded} / {predicted_embedded} → {embedded_precision:.2%}\" if embedded_precision is not None else \"🔸 No embedded clauses predicted.\")\n",
    "\n",
    "print(f\"🔹 Non-embedded precision: {matched_non_embedded} / {predicted_non_embedded} → {non_embedded_precision:.2%}\" if non_embedded_precision is not None else \"🔹 No non-embedded clauses predicted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d50081-b01d-4721-a221-11f68f4fdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_by_clause_type(df, clause_type=\"embedded\"):\n",
    "    total_predicted = 0\n",
    "    total_matched = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        gold_set = set(row[\"gold_clauses\"])\n",
    "        embedded_set = set(row[\"embedded_clauses\"])\n",
    "        predicted = row[\"predicted_clauses\"]\n",
    "\n",
    "        for clause in predicted:\n",
    "            if clause_type == \"embedded\" and clause in embedded_set:\n",
    "                total_predicted += 1\n",
    "                if clause in gold_set:\n",
    "                    total_matched += 1\n",
    "            elif clause_type == \"non_embedded\" and clause not in embedded_set:\n",
    "                total_predicted += 1\n",
    "                if clause in gold_set:\n",
    "                    total_matched += 1\n",
    "\n",
    "    label = \"Embedded\" if clause_type == \"embedded\" else \"Non-embedded\"\n",
    "    print(f\"\\n📘 Precision Summary – {label} Clauses\")\n",
    "    print(f\"Predicted {label.lower()} clauses: {total_predicted}\")\n",
    "    print(f\"Correctly predicted {label.lower()} clauses: {total_matched}\")\n",
    "    if total_predicted:\n",
    "        print(f\"📐 Precision: {total_matched / total_predicted:.2%}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No {label.lower()} clauses predicted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32765b77-75b0-4228-9896-949d320d6c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870ff75-b7e5-437c-b1be-ed0a5db31208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
